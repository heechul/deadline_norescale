diff --git a/kernel/sched/features.h b/kernel/sched/features.h
index a3d331dd2..090dabf6a 100644
--- a/kernel/sched/features.h
+++ b/kernel/sched/features.h
@@ -37,6 +37,12 @@ SCHED_FEAT(NEXT_BUDDY, false)
  */
 SCHED_FEAT(CACHE_HOT_BUDDY, true)
 
+/*
+ * Enable DEADLINE scheduler's admission control system (ACS)
+ * NOTE: this feature is disabled by default
+ */
+SCHED_FEAT(DEADLINE_ACS, false)
+
 /*
  * Delay dequeueing tasks until they get selected or woken.
  *
diff --git a/kernel/sched/syscalls.c b/kernel/sched/syscalls.c
index ff0e5ab4e..1a0f91bb1 100644
--- a/kernel/sched/syscalls.c
+++ b/kernel/sched/syscalls.c
@@ -652,7 +652,7 @@ int __sched_setscheduler(struct task_struct *p,
 		}
 #endif
 #ifdef CONFIG_SMP
-		if (dl_bandwidth_enabled() && dl_policy(policy) &&
+		if (sched_feat(DEADLINE_ACS) && dl_bandwidth_enabled() && dl_policy(policy) &&
 				!(attr->sched_flags & SCHED_FLAG_SUGOV)) {
 			cpumask_t *span = rq->rd->span;
 
@@ -684,7 +684,7 @@ int __sched_setscheduler(struct task_struct *p,
 	 * of a SCHED_DEADLINE task) we need to check if enough bandwidth
 	 * is available.
 	 */
-	if ((dl_policy(policy) || dl_task(p)) && sched_dl_overflow(p, policy, attr)) {
+	if (sched_feat(DEADLINE_ACS) && (dl_policy(policy) || dl_task(p)) && sched_dl_overflow(p, policy, attr)) {
 		retval = -EBUSY;
 		goto unlock;
 	}
@@ -1146,7 +1146,8 @@ int dl_task_check_affinity(struct task_struct *p, const struct cpumask *mask)
 	 * root_domain.
 	 */
 	guard(rcu)();
-	if (!cpumask_subset(task_rq(p)->rd->span, mask))
+
+	if (sched_feat(DEADLINE_ACS) && !cpumask_subset(task_rq(p)->rd->span, mask))
 		return -EBUSY;
 
 	return 0;
